{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aef6351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Dario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc88c70",
   "metadata": {},
   "source": [
    "### Load Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffc27f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "966"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = [\"Hate\", \"Normal\", \"Offensive\"]\n",
    "dfs = []\n",
    "\n",
    "for cls in classes:\n",
    "    for i in range(1, 5):  # files 1 to 4\n",
    "        file_name = f\"{cls}_Speeches_{i}.csv\"\n",
    "        tmp = pd.read_csv(file_name, usecols=[\"created_at\", \"full_text\"])\n",
    "        tmp[\"class\"] = cls\n",
    "        dfs.append(tmp)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "len(df[df[\"class\"] == \"Hate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d801a0a4",
   "metadata": {},
   "source": [
    "### Case 1: Chi-Squared\n",
    "For this case we will do some preprocessing for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f29ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    text = re.sub(r'[^a-z\\s]', '', text.lower())\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc if \n",
    "                     (token.pos_ == \"NOUN\" or token.pos_ == \"ADJ\") and \n",
    "                     not token.is_stop and \n",
    "                     len(token) > 2 and\n",
    "                     not re.search(r\"\\d\", token.text)]) # The token does not contain digits\n",
    "\n",
    "\n",
    "chi2_results = {}\n",
    "\n",
    "texts = df[\"full_text\"].astype(str).tolist()\n",
    "labels = (df[\"class\"] == \"Hate\").astype(int).values  # 1 = Hate, 0 = Non-Hate\n",
    "\n",
    "# Vectorize with adaptive min_df\n",
    "min_df_val = min(5, max(1, len(df)//10))\n",
    "count_vec = CountVectorizer(min_df=min_df_val, ngram_range=(1,1))\n",
    "X_count = count_vec.fit_transform(texts)\n",
    "\n",
    "\n",
    "vocab = np.array(count_vec.get_feature_names_out())\n",
    "\n",
    "# ChiÂ² test\n",
    "chi2_scores, pvals = chi2(X_count, labels)\n",
    "\n",
    "# Compute per-class counts\n",
    "counts_hate = np.asarray(X_count[labels == 1].sum(axis=0)).ravel()\n",
    "counts_nonhate = np.asarray(X_count[labels == 0].sum(axis=0)).ravel()\n",
    "preferred_class = np.where(counts_hate > counts_nonhate, \"Hate\", \"Non-Hate\")\n",
    "\n",
    "# Build dataframe\n",
    "chi2_df = pd.DataFrame({\n",
    "    \"word\": vocab,\n",
    "    \"chi2\": chi2_scores,\n",
    "    \"pval\": pvals,\n",
    "    \"counts_hate\": counts_hate,\n",
    "    \"counts_nonhate\": counts_nonhate,\n",
    "    \"preferred_class\": preferred_class\n",
    "}).sort_values(\"chi2\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5217db",
   "metadata": {},
   "source": [
    "Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a8915f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>chi2</th>\n",
       "      <th>pval</th>\n",
       "      <th>counts_hate</th>\n",
       "      <th>counts_nonhate</th>\n",
       "      <th>preferred_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>seoul</td>\n",
       "      <td>30.362319</td>\n",
       "      <td>3.584235e-08</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>mass</td>\n",
       "      <td>30.362319</td>\n",
       "      <td>3.584235e-08</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849</th>\n",
       "      <td>started</td>\n",
       "      <td>28.261857</td>\n",
       "      <td>1.059636e-07</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>coz</td>\n",
       "      <td>28.193582</td>\n",
       "      <td>1.097680e-07</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>negativity</td>\n",
       "      <td>27.391171</td>\n",
       "      <td>1.661883e-07</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>biu</td>\n",
       "      <td>26.445745</td>\n",
       "      <td>2.710449e-07</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>crimes</td>\n",
       "      <td>26.024845</td>\n",
       "      <td>3.370519e-07</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>qrt</td>\n",
       "      <td>26.024845</td>\n",
       "      <td>3.370519e-07</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>jantarmantar</td>\n",
       "      <td>26.024845</td>\n",
       "      <td>3.370519e-07</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>struggle</td>\n",
       "      <td>26.024845</td>\n",
       "      <td>3.370519e-07</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>targeting</td>\n",
       "      <td>26.024845</td>\n",
       "      <td>3.370519e-07</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>tryna</td>\n",
       "      <td>26.024845</td>\n",
       "      <td>3.370519e-07</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>expose</td>\n",
       "      <td>26.024845</td>\n",
       "      <td>3.370519e-07</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>killed</td>\n",
       "      <td>25.282955</td>\n",
       "      <td>4.950644e-07</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>english</td>\n",
       "      <td>25.185064</td>\n",
       "      <td>5.208402e-07</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>gone</td>\n",
       "      <td>24.772859</td>\n",
       "      <td>6.449929e-07</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>laws</td>\n",
       "      <td>24.081588</td>\n",
       "      <td>9.233897e-07</td>\n",
       "      <td>23</td>\n",
       "      <td>9</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>myself</td>\n",
       "      <td>23.979480</td>\n",
       "      <td>9.736790e-07</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>lk</td>\n",
       "      <td>23.856108</td>\n",
       "      <td>1.038120e-06</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word       chi2          pval  counts_hate  counts_nonhate  \\\n",
       "1748         seoul  30.362319  3.584235e-08           14               0   \n",
       "1255          mass  30.362319  3.584235e-08           14               0   \n",
       "1849       started  28.261857  1.059636e-07           23               7   \n",
       "483            coz  28.193582  1.097680e-07           13               0   \n",
       "1367    negativity  27.391171  1.661883e-07           16               2   \n",
       "266            biu  26.445745  2.710449e-07           17               3   \n",
       "490         crimes  26.024845  3.370519e-07           12               0   \n",
       "1583           qrt  26.024845  3.370519e-07           12               0   \n",
       "1082  jantarmantar  26.024845  3.370519e-07           12               0   \n",
       "1865      struggle  26.024845  3.370519e-07           12               0   \n",
       "1908     targeting  26.024845  3.370519e-07           12               0   \n",
       "2017         tryna  26.024845  3.370519e-07           12               0   \n",
       "721         expose  26.024845  3.370519e-07           12               0   \n",
       "1122        killed  25.282955  4.950644e-07           15               2   \n",
       "674        english  25.185064  5.208402e-07           19               5   \n",
       "870           gone  24.772859  6.449929e-07           20               6   \n",
       "1152          laws  24.081588  9.233897e-07           23               9   \n",
       "1347        myself  23.979480  9.736790e-07           24              10   \n",
       "1200            lk  23.856108  1.038120e-06           11               0   \n",
       "\n",
       "     preferred_class  \n",
       "1748            Hate  \n",
       "1255            Hate  \n",
       "1849            Hate  \n",
       "483             Hate  \n",
       "1367            Hate  \n",
       "266             Hate  \n",
       "490             Hate  \n",
       "1583            Hate  \n",
       "1082            Hate  \n",
       "1865            Hate  \n",
       "1908            Hate  \n",
       "2017            Hate  \n",
       "721             Hate  \n",
       "1122            Hate  \n",
       "674             Hate  \n",
       "870             Hate  \n",
       "1152            Hate  \n",
       "1347            Hate  \n",
       "1200            Hate  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_df[chi2_df[\"preferred_class\"] == \"Hate\"][21:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786c4cbf",
   "metadata": {},
   "source": [
    "### Case 2: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dd2a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words='english',      # remove common words (optional)\n",
    "    ngram_range=(1,1),        # unigrams + bigrams\n",
    "    #min_df=5                   # ignore very rare terms\n",
    ")\n",
    "\n",
    "\n",
    "# Computing TF-IDF Matrix\n",
    "X = vectorizer.fit_transform(df[\"full_text\"])\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "\n",
    "hate_idx = df[\"class\"] == \"Hate\"\n",
    "nonhate_idx = df[\"class\"] != \"Hate\"\n",
    "\n",
    "# Computing mean TF-IDF for each class\n",
    "mean_hate = X[hate_idx].mean(axis=0).A1\n",
    "mean_nonhate = X[nonhate_idx].mean(axis=0).A1\n",
    "\n",
    "diff = mean_hate - mean_nonhate\n",
    "\n",
    "# Top words\n",
    "top_n = 60\n",
    "top_idx = np.argsort(diff)[-top_n:]\n",
    "\n",
    "top_words = pd.DataFrame({\n",
    "    \"word\": feature_names[top_idx],\n",
    "    \"tfidf_diff\": diff[top_idx],\n",
    "    \"mean_hate\": mean_hate[top_idx],\n",
    "    \"mean_nonhate\": mean_nonhate[top_idx]\n",
    "}).sort_values(\"tfidf_diff\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "647fa152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tfidf_diff</th>\n",
       "      <th>mean_hate</th>\n",
       "      <th>mean_nonhate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>hate</td>\n",
       "      <td>0.090646</td>\n",
       "      <td>0.096393</td>\n",
       "      <td>0.005746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>https</td>\n",
       "      <td>0.015005</td>\n",
       "      <td>0.048358</td>\n",
       "      <td>0.033353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>love</td>\n",
       "      <td>0.012441</td>\n",
       "      <td>0.017264</td>\n",
       "      <td>0.004822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>hatespeech</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>india</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.007157</td>\n",
       "      <td>0.000564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>video</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.007921</td>\n",
       "      <td>0.002244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>reading</td>\n",
       "      <td>0.005666</td>\n",
       "      <td>0.006076</td>\n",
       "      <td>0.000410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>hindu</td>\n",
       "      <td>0.005576</td>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.000154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>delhi</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>spreading</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.000826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>seoul</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.004966</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>laws</td>\n",
       "      <td>0.004504</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>report</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.001974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>gone</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>let</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.003991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>hateful</td>\n",
       "      <td>0.003925</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>hindurashtra</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>bigotry</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.003865</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>unsaid</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>chatting</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>started</td>\n",
       "      <td>0.003789</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.000610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>english</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>qrt</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.003749</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>jv8lzf438b</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>nice</td>\n",
       "      <td>0.003698</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.001060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>comments</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.031151</td>\n",
       "      <td>0.027489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>biu</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.003927</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>trans</td>\n",
       "      <td>0.003571</td>\n",
       "      <td>0.005411</td>\n",
       "      <td>0.001840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>remember</td>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>somaliland</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sejun</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>jantarmantar</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>negativity</td>\n",
       "      <td>0.003335</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.000164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>song</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>actually</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005984</td>\n",
       "      <td>0.002683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>leave</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>0.003639</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>defamation</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.003272</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>mass</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.003253</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>killed</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.003427</td>\n",
       "      <td>0.000194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>doing</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.000922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>groups</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>story</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.003716</td>\n",
       "      <td>0.000505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>years</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stopped</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>crimes</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dak</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>coz</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>parishad</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>know</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.007979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spread</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>care</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.000804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>violent</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rose</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anthonny</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.003036</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>musk</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>reporting</td>\n",
       "      <td>0.003028</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buy</td>\n",
       "      <td>0.003025</td>\n",
       "      <td>0.003398</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muslims</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.001757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bbtitans</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.003710</td>\n",
       "      <td>0.000725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>giving</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.004783</td>\n",
       "      <td>0.001800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  tfidf_diff  mean_hate  mean_nonhate\n",
       "59          hate    0.090646   0.096393      0.005746\n",
       "58         https    0.015005   0.048358      0.033353\n",
       "57          love    0.012441   0.017264      0.004822\n",
       "56    hatespeech    0.010400   0.010400      0.000000\n",
       "55         india    0.006593   0.007157      0.000564\n",
       "54         video    0.005677   0.007921      0.002244\n",
       "53       reading    0.005666   0.006076      0.000410\n",
       "52         hindu    0.005576   0.005730      0.000154\n",
       "51         delhi    0.005504   0.005504      0.000000\n",
       "50     spreading    0.005001   0.005826      0.000826\n",
       "49         seoul    0.004966   0.004966      0.000000\n",
       "48          laws    0.004504   0.005210      0.000706\n",
       "47        report    0.004445   0.006419      0.001974\n",
       "46          gone    0.004084   0.004653      0.000569\n",
       "45           let    0.003944   0.007935      0.003991\n",
       "44       hateful    0.003925   0.004123      0.000199\n",
       "43  hindurashtra    0.003869   0.003869      0.000000\n",
       "42       bigotry    0.003865   0.003865      0.000000\n",
       "41        unsaid    0.003827   0.003827      0.000000\n",
       "40      chatting    0.003827   0.003827      0.000000\n",
       "39       started    0.003789   0.004399      0.000610\n",
       "38       english    0.003781   0.004196      0.000416\n",
       "37           qrt    0.003749   0.003749      0.000000\n",
       "36    jv8lzf438b    0.003739   0.003739      0.000000\n",
       "35          nice    0.003698   0.004758      0.001060\n",
       "34      comments    0.003662   0.031151      0.027489\n",
       "33           biu    0.003622   0.003927      0.000305\n",
       "32         trans    0.003571   0.005411      0.001840\n",
       "31      remember    0.003551   0.004458      0.000907\n",
       "30    somaliland    0.003473   0.003473      0.000000\n",
       "29         sejun    0.003390   0.003390      0.000000\n",
       "28  jantarmantar    0.003362   0.003362      0.000000\n",
       "27    negativity    0.003335   0.003499      0.000164\n",
       "26          song    0.003305   0.003305      0.000000\n",
       "25      actually    0.003300   0.005984      0.002683\n",
       "24         leave    0.003280   0.003639      0.000359\n",
       "23    defamation    0.003272   0.003272      0.000000\n",
       "22          mass    0.003253   0.003253      0.000000\n",
       "21        killed    0.003233   0.003427      0.000194\n",
       "20         doing    0.003218   0.004140      0.000922\n",
       "19        groups    0.003216   0.003216      0.000000\n",
       "18         story    0.003211   0.003716      0.000505\n",
       "17         years    0.003199   0.004561      0.001362\n",
       "16       stopped    0.003184   0.003184      0.000000\n",
       "15        crimes    0.003184   0.003184      0.000000\n",
       "14           dak    0.003123   0.003123      0.000000\n",
       "13           coz    0.003123   0.003123      0.000000\n",
       "12      parishad    0.003118   0.003118      0.000000\n",
       "11          know    0.003093   0.011071      0.007979\n",
       "10        spread    0.003092   0.003467      0.000375\n",
       "9           care    0.003076   0.003880      0.000804\n",
       "8        violent    0.003076   0.003076      0.000000\n",
       "7           rose    0.003060   0.003417      0.000357\n",
       "6       anthonny    0.003036   0.003036      0.000000\n",
       "5           musk    0.003033   0.003033      0.000000\n",
       "4      reporting    0.003028   0.003234      0.000206\n",
       "3            buy    0.003025   0.003398      0.000373\n",
       "2        muslims    0.002998   0.004755      0.001757\n",
       "1       bbtitans    0.002985   0.003710      0.000725\n",
       "0         giving    0.002983   0.004783      0.001800"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26c01b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
