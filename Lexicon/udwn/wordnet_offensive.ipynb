{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7afa4e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ass', 'asshole', 'assholes', 'bastard', 'bastards', 'bitch', 'bitches', 'cock', 'cocks', 'CockSucker', 'crap', 'cunt', 'cunts', 'dick', 'dyke', 'fag', 'faggot', 'fags', 'fart', 'fuck', 'fucker', 'fucking', 'fucks', 'gay', 'hells', 'hoar', 'knob', 'knobs', 'Lesbian', 'pecker', 'pussy', 'queer', 'queers', 'retard', 'screwing', 'sex', 'sexy', 'shit', 'shits', 'skank', 'skanks', 'slut', 'sluts', 'tit', 'whore', 'xxx', 'bitch', 'fuck', 'shit', 'ass', 'asshole', 'bastard', 'chink', 'cock', 'cunt', 'lesbian', 'masturbate', 'nazi', 'pussy', 'slut', 'smut', 'tits', 'boobs', 'wank', 'whore', 'breasts', 'fanny', 'foreskin', 'gay', 'gook', 'hell', 'nazis', 'poop', 'preteen', 'screw', 'spic', 'twat']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "df = pd.read_csv('badwords.txt', header=None)\n",
    "\n",
    "polys = []\n",
    "for _, row in df.iterrows():\n",
    "    if len(wn.synsets(row[0])) > 1:\n",
    "        polys.append(row[0])\n",
    "\n",
    "print(polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aef12b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ricerca synset offensivi: 100%|██████████| 117659/117659 [00:00<00:00, 974659.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trovati 49 synset offensivi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Categorie disponibili: 'disparagement', 'ethnic_slur', 'obscenity'\n",
    "offensive_synsets = []\n",
    "\n",
    "# Converti il generatore in lista per conoscere la lunghezza totale\n",
    "all_synsets = list(wordnet.all_synsets())\n",
    "\n",
    "for synset in tqdm(all_synsets, desc=\"Ricerca synset offensivi\"):\n",
    "    # Verificare se il synset ha una nota di usage offensiva\n",
    "    if hasattr(synset, 'usage_domains'):\n",
    "        usage = synset.usage_domains()\n",
    "        for domain in usage:\n",
    "            if 'disparagement' in domain.name() or \\\n",
    "               'ethnic_slur' in domain.name() or \\\n",
    "               'obscenity' in domain.name() or \\\n",
    "               'vulgarity' in domain.name():\n",
    "                offensive_synsets.append(synset)\n",
    "                break\n",
    "\n",
    "print(f\"\\nTrovati {len(offensive_synsets)} synset offensivi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "262da4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trovati 383 termini offensivi basati sulla definizione\n"
     ]
    }
   ],
   "source": [
    "keywords = ['offensive', 'obscene', 'curse', 'slang', 'vulgar', 'derogatory', 'insult', 'offense', 'profanity', 'abusive', 'pejorative', 'disparaging', 'rude']\n",
    "\n",
    "offensive_terms = []\n",
    "\n",
    "for synset in wordnet.all_synsets():\n",
    "    definition = synset.definition().lower()\n",
    "    #check if it is an adjective or noun\n",
    "    if synset.pos() not in ['a', 's', 'n']:\n",
    "        continue\n",
    "    domains = [domain.name() for domain in synset.usage_domains()]\n",
    "    if any(keyword in definition for keyword in keywords) or any(usage in domain for domain in domains for usage in ['disparagement', 'ethnic_slur', 'obscenity']) :\n",
    "        offensive_terms.append(synset)\n",
    "\n",
    "print(f\"Trovati {len(offensive_terms)} termini offensivi basati sulla definizione\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be297bfb",
   "metadata": {},
   "source": [
    "Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc98816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ss in offensive_terms:\n",
    "    print(f\"Synset: {ss.name()}\")\n",
    "    print(f\"Definizione: {ss.definition()}\")\n",
    "    print(f\"Lemmi: {ss.lemma_names()}\")\n",
    "    print(f\"Esempi: {ss.examples()}\")\n",
    "    print(\"Usage domains:\", [domain.name() for domain in ss.usage_domains()])\n",
    "    print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
